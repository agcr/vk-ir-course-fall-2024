{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclick.click_models.Evaluation import LogLikelihood, Perplexity\n",
    "\n",
    "from pyclick.click_models.SDBN import SDBN\n",
    "from pyclick.click_models.CTR import GCTR\n",
    "\n",
    "from session_storage import SessionStorage\n",
    "\n",
    "# на предупреждение можно не обращать внимания. Оно в assert-те и не влияет на работоспособность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Простейшая обертка. Подробнее о логике работы см. в doc-string в session_storage.py\n",
    "ya_storage = SessionStorage(\"./data/YandexRelPredChallenge.txt\")\n",
    "vk_storage = SessionStorage(\"./data/VKVideoClickSessions.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно поучить различные модели. Алгоритмы в библиотеке повторяют псевдокод из статей и книг, однако не оптимизированы.\n",
    "\n",
    "Заметим, что можно обучать модель на непересекающихся запросах можно совершенно свободно. То есть, либо уча несколько моделей параллельно, либо исполняя параллельно непосредственно сами итерации обучения внутри одной модели, мы получили бы идентичные результаты.\n",
    "\n",
    "Для академических задач вполне хватит и синхронных реализаций из PyClick. \n",
    "\n",
    "Однако, чтобы не ждать слишком долго, на семинаре мы познакомимся с достаточно \"быстрыми\" моделями.\n",
    "\n",
    "На лекции говорилось, что у DBN есть параметр $\\gamma$, который, по-хорошему, следует подбирать под каждый датасет.\n",
    "\n",
    "Однако сами же авторы признают, что лучшие результаты получаются при значение $\\gamma$ около 0.95, а задание $\\gamma = 1$ сильно упрощает расчеты, при этом не сильно теряя в качестве.\n",
    "\n",
    "DBN с фиксированным $\\gamma = 1$ называется SDBN и работает куда быстрее. Именно такую версию мы и будем использовать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выбираем кликовую модель \n",
    "ya_model = SDBN()\n",
    "# Как и другие модели обучаем на тренировочном множестве, а проверять работу -- на тестовом\n",
    "ya_model.train(ya_storage.get_train_sessions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, работает достаточно быстро для ~14k сессий.\n",
    "\n",
    "Теперь оценим качество получившейся модели на тестовом множестве.\n",
    "\n",
    "Для оценки качества используется перплексия. Она считается по каждой позиции:\n",
    "\n",
    "$$\n",
    "PPL@j = 2^{-\\frac{1}{N}\\sum_{i=1}^{N}c_{i,j}\\log\\mathcal{P}_{i,j} + (1 - c_{i,j})\\log(1 - \\mathcal{P}_{i,j}) },\n",
    "$$\n",
    "где $N$ -- количество запросов, $c_{i,j}$ метка фактически совершенного клика по запросу $i$ на позиции в серпе $j$, а $\\mathcal{P}_{i,j}$ -- вероятность такого клика, которую предсказала наша модель\n",
    "\n",
    "средняя перплексия по всем позициям ($M$ - длина серпа)\n",
    "\n",
    "$$\n",
    "PPL = \\frac{1}{M} \\cdot \\sum_{j=1}^{M} PPL@j\n",
    "$$\n",
    "\n",
    "Само по себе значение перплексии о качестве модели говорит мало, но её можно использовать для сравнения моделей между собой. Чем ниже перплексия -- тем лучше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, storage):\n",
    "    log_likelihood = LogLikelihood()\n",
    "    perplexity = Perplexity()\n",
    "\n",
    "    print(f\"LL\\t=\\t{log_likelihood.evaluate(model, storage.get_test_sessions())}\")\n",
    "\n",
    "    # Перплексия считается для каждой позиции (PPL@j)\n",
    "    # Под индексом 1 лежит список перплексий по позициям\n",
    "    # Под индексом 0 лежит средняя перплексия, именно по ней мы и будем сравнивать модели\n",
    "\n",
    "    print(f\"PPL\\t=\\t{perplexity.evaluate(model, storage.get_test_sessions())[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL\t=\t-0.3033771682116208\n",
      "PPL\t=\t1.3353151793972282\n"
     ]
    }
   ],
   "source": [
    "eval_model(ya_model, ya_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Повторим аналогичную процедуру на датасете VK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL\t=\t-0.21916613507449373\n",
      "PPL\t=\t1.2893631037811262\n"
     ]
    }
   ],
   "source": [
    "vk_model = SDBN()\n",
    "vk_model.train(vk_storage.get_train_sessions())\n",
    "\n",
    "eval_model(vk_model, vk_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно, у модели на датасете VK PPL получилось меньше, LL больше.\n",
    "\n",
    "Значит ли это, что она лучше?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим простейшую CTR-based модель, которая была первой на лекции.\n",
    "\n",
    "Модель основана на простом подсчете доли кликов в документ, т.е. расчет этой доли на тренировочном множестве дает нам оценку вероятности клика на документ по запросу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL\t=\t-0.3829820592200756\n",
      "PPL\t=\t1.5553359036805376\n"
     ]
    }
   ],
   "source": [
    "ya_ctr_model = GCTR()\n",
    "ya_ctr_model.train(ya_storage.get_train_sessions())\n",
    "\n",
    "eval_model(ya_ctr_model, ya_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество существенно отличается в худшую сторону, в том числе и для VK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LL\t=\t-0.41639661047756865\n",
      "PPL\t=\t1.6643166426006182\n"
     ]
    }
   ],
   "source": [
    "vk_ctr_model = GCTR()\n",
    "vk_ctr_model.train(vk_storage.get_train_sessions())\n",
    "\n",
    "eval_model(vk_ctr_model, vk_storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, у нас есть обученная модель, которая несколько лучше других предсказывает вероятность клика в документ по запросу. Как нам получить эту вероятность для конкретного документа по конкретному запросу?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relevant\t(id 522843)\t=\t0.5448891448315577\n",
      "irrelevant\t(id 522983)\t=\t0.375\n"
     ]
    }
   ],
   "source": [
    "# Возьмем какой-нибудь запрос, для этого можно заглянуть в storage.get_test_queries() и выбрать тот, который больше нравится\n",
    "\n",
    "query = '102845'\n",
    "\n",
    "# А также нам понадобится какой-нибудь документ.\n",
    "# Возьмем несколько документов:\n",
    "# самый закликанный. модель, очевидно, должна считать его релевантным\n",
    "relevant_document = vk_storage.get_document(query=query, is_clicked=True)\n",
    "\n",
    "# наименее закликанный, но из того же серпа, то есть менее релевантный\n",
    "irrelevant_document = vk_storage.get_document(query=query, is_clicked=False)\n",
    "\n",
    "# и посмотрим на оценки, которые модель дает таким документам по данному запросу\n",
    "\n",
    "print(f\"relevant\\t(id {relevant_document})\\t=\\t{vk_model.predict_relevance(query, relevant_document)}\")\n",
    "print(f\"irrelevant\\t(id {irrelevant_document})\\t=\\t{vk_model.predict_relevance(query, irrelevant_document)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученные модели можно сохранять и переиспользовать без обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обратите внимание: у моделей уже реализованы to_json() и from_json(str) методы\n",
    "# поэтому достаточно сохранить одну json-строку\n",
    "with open(\"./vk_sdbn_model.json\", \"w\", encoding=\"utf-8\") as f_out:\n",
    "    f_out.write(vk_model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vk_model = SDBN()\n",
    "\n",
    "# прочесть также достаточно только одну строку\n",
    "with open(\"./vk_sdbn_model.json\", \"r\", encoding=\"utf-8\") as f_in:\n",
    "    for line in f_in:\n",
    "        vk_model.from_json(line)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
