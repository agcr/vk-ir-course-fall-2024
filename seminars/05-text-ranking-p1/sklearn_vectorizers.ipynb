{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c68b6411-668d-431f-9556-9a478597aa6c",
   "metadata": {},
   "source": [
    "# Векторизаторы из библиотеки scikit-learn\n",
    "\n",
    "В этом тюториале мы научимся:\n",
    "- пользоваться векторизаторами из библиотеки _scikit-learn_\n",
    "- превращать коллекцию текстов в матрицу термин-документ\n",
    "- векторизовывать тексты в виде векторов взвешенных по TF-IDF\n",
    "- ранжировать документы с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0a7027-7d31-480c-9e05-44b6ca966f68",
   "metadata": {},
   "source": [
    "Импортируем модули которые нам понадобятся впоследствии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fb783d-937e-40a6-88b5-3df49b614a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import pairwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bd5f69-0f93-4a21-8aa6-62744c5e6476",
   "metadata": {},
   "source": [
    "Предположим, что на входе нам дана коллекция из нескольких текстовых документов (названия институтов):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84b812b-f9bd-41dd-96dc-3007b4efe5e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Московская государственная академия хореографии', 'Московский государственный университет им. М.В. Ломоносова (Университет МГУ)', 'Московский физико-технический институт (национальный исследовательский университет)', 'Национальный исследовательский университет «МИЭТ»', 'Национальный исследовательский университет ИТМО']\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"Московская государственная академия хореографии\",\n",
    "    \"Московский государственный университет им. М.В. Ломоносова (Университет МГУ)\",\n",
    "    \"Московский физико-технический институт (национальный исследовательский университет)\",\n",
    "    \"Национальный исследовательский университет «МИЭТ»\",\n",
    "    \"Национальный исследовательский университет ИТМО\",\n",
    "]\n",
    "print(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d8801e-39dd-4844-9240-9a71c3625e83",
   "metadata": {},
   "source": [
    "## Матрица термин-документ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ef0386-af81-4cd3-821f-b2a28d839171",
   "metadata": {},
   "source": [
    "Превратим нашу коллекцию текстов в матрицу термин-документ с помощью класса _CountVectorizer_ из библиотеки _scikit_learn_.\n",
    "\n",
    "Сначала нам потребуется создать объект класса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70f8c76e-e7f9-43f3-9c0d-d9076d242a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=1, binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457e6d90-1111-40cd-a2ce-f2a6a2bc580e",
   "metadata": {},
   "source": [
    "Передаем в конструктор объекта параметры:\n",
    "- _min_df_ -- порог на документную частоту, т.е. на число документов, в которых встречается данное слово. Векторизатор будет игнорировать редкие слова с частотой меньше, чем min_df. Мы, в данном случае, хотим оставить все слова.\n",
    "- _binary_ -- бинаризовать TFы (частоты слов). По дефолту векторизатор хранит в каждой ячейке матрицы термин-документ TF, т.е. сколько раз данный термин встречается в данном документе. Параметр binary=True заставляет векторизатор использовать вместо TFов значения 0 или 1.\n",
    "\n",
    "Полный список возможных параметров (их множество!) можно найти на страничке с документацией: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07def150-f9b2-4d2d-8bb8-01b526dc08b2",
   "metadata": {},
   "source": [
    "Теперь \"обучим\" наш векторизатор на текстах, и распечатаем получившуюся матрицу термин-документ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67fb4cd6-6a57-4f33-81c5-74bf492aef01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 25 stored elements and shape (5, 17)>\n",
      "  Coords\tValues\n",
      "  (0, 10)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 0)\t1\n",
      "  (0, 16)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 15)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 12)\t1\n",
      "  (2, 5)\t1\n",
      "  (3, 14)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 5)\t1\n",
      "  (3, 9)\t1\n",
      "  (4, 14)\t1\n",
      "  (4, 12)\t1\n",
      "  (4, 5)\t1\n",
      "  (4, 6)\t1\n"
     ]
    }
   ],
   "source": [
    "X = vectorizer.fit_transform(texts)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab54e72-f327-4808-b41c-fa05514bf3ae",
   "metadata": {},
   "source": [
    "Обратим тут внимание на два момента.\n",
    "\n",
    "Во-первых, мы вызываем функцию _fit_transform()_, т.е. сразу и обучаем векторизатор, и векторизуем наши тексты. Эти два этапа можно разделить, т.е. сначала обучать векторизатор вызовом _fit()_, а потом применять его для векторизации каких-то других текстов с помощью функции _transform_(). Дальше мы увидим как все это работает на примерах.\n",
    "\n",
    "Во-вторых, на выходе у нас не обычный numpy array, а что-то странное.<br>\n",
    "Посмотрим на тип объекта X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "644721a6-82ff-4a06-89ab-db2a58f3b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697d0810-0356-47d3-84ff-91823c0700d6",
   "metadata": {},
   "source": [
    "Видим, что тут используются классы для представления разреженных (sparse) матриц из библиотеки scipy.\n",
    "\n",
    "Эти классы описаны в документации: https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html\n",
    "\n",
    "Мотивация тут очень простая -- мы векторизуем наши тексты так, что:\n",
    "- каждый текст представляется в виде вектора длиной размера словаря, т.е. для большой коллекции текстов это могут быть сотни тысяч или даже миллионы слов (терминов)\n",
    "- в каждом конкретном векторе у нас выставлены в 1 только те элементы, которые соответствуют словам, которые были в данном тексте, а их, как правило, гораздо меньше чем полное количество известных нам слов => вектора получаются очень разреженные.\n",
    "\n",
    "Посмотрим еще раз на размеры нашей матрицы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6002a6b2-a141-43b5-87cd-87138ef0b1c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 17)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3701a8ce-798a-4eb5-88fa-aa5495066240",
   "metadata": {},
   "source": [
    "Т.е. у нас всего 5 документов и 17 уникальных слов в словаре.\n",
    "\n",
    "А сколько у нас ненулевых элементов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e57ed38-282a-4e35-95fe-13e53f5f0b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(X.nnz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae6d4dc-90c1-4d87-bf1d-65d31dd1824e",
   "metadata": {},
   "source": [
    "У нас всего 265 ненулевых элемента, т.е. матрица заполнена всего на 25 / (5 * 17) = 29.4%.\n",
    "\n",
    "А если бы наша коллекция была больше, то эта заполненность была бы еще во много-много раз ниже.\n",
    "\n",
    "Посмотрим на нашу матрицу в более удобном виде:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b6d9cf8-0699-4ce0-ac11-8c4fd756c165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1]\n",
      " [0 0 1 1 0 0 0 1 1 0 0 1 0 0 1 0 0]\n",
      " [0 0 0 0 1 1 0 0 0 0 0 1 1 1 1 1 0]\n",
      " [0 0 0 0 0 1 0 0 0 1 0 0 1 0 1 0 0]\n",
      " [0 0 0 0 0 1 1 0 0 0 0 0 1 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afee7523-8a85-4d2d-8f1e-5693b00637fb",
   "metadata": {},
   "source": [
    "Теперь мы видим ее в типичном представлении матрицы термин-документ, где:\n",
    "- каждая строка соответствует документу\n",
    "- каждый столбец соответствует слову из словаря\n",
    "\n",
    "Как понять каким конкретно словам соответсвуют столбцы?\n",
    "\n",
    "Для этого можно воспользоваться свойством векторизатора vocabulary_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75155b0b-9639-434b-8484-e2699b152d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'московская': 10, 'государственная': 1, 'академия': 0, 'хореографии': 16, 'московский': 11, 'государственный': 2, 'университет': 14, 'им': 3, 'ломоносова': 7, 'мгу': 8, 'физико': 15, 'технический': 13, 'институт': 4, 'национальный': 12, 'исследовательский': 5, 'миэт': 9, 'итмо': 6}\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ee2493-0db5-4e6a-b3a1-5c2dd3f90fbc",
   "metadata": {},
   "source": [
    "Мы видим, что словарь представляет из себя словарь, отображающий слово в позицию, т.е. например:\n",
    "- слово \"академия\" соответсвует 0-му столбцу\n",
    "- слово \"государственная\" 1-му и т.д.\n",
    "\n",
    "Также, словарь можно распечатать в уже упорядоченном виде с помощью метода _get_feature_names_out()_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1816820-1698-475e-a317-9c3499c9cbfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['академия' 'государственная' 'государственный' 'им' 'институт'\n",
      " 'исследовательский' 'итмо' 'ломоносова' 'мгу' 'миэт' 'московская'\n",
      " 'московский' 'национальный' 'технический' 'университет' 'физико'\n",
      " 'хореографии']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c9099-9e93-4878-af2f-98f8d1045a1d",
   "metadata": {},
   "source": [
    "Обратим внимание, что в этом списке слов есть далеко не все слова исходных текстов, напр. куда-то пропали однобуквенные слова из названия института \"университет им. М.В. Ломоносова\".\n",
    "\n",
    "Дело в том, что наш векторизатор \"под капотом\" предобрабатывает текст, в т.ч.:\n",
    "- понижает регистр\n",
    "- токенизирует текст с помощью встроенного токенизатора\n",
    "\n",
    "Все эти этапы, при желании, можно кастомизировать.\n",
    "\n",
    "Предположим, что мы не хотим терять однословные слова. В этом случае будет достаточно кастомизировать токенизатор, передав ему наш собственный _token_pattern_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4bad76b6-945f-4ed4-9e62-5e4e99d15d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 19)\n",
      "['академия' 'в' 'государственная' 'государственный' 'им' 'институт'\n",
      " 'исследовательский' 'итмо' 'ломоносова' 'м' 'мгу' 'миэт' 'московская'\n",
      " 'московский' 'национальный' 'технический' 'университет' 'физико'\n",
      " 'хореографии']\n"
     ]
    }
   ],
   "source": [
    "# Rewrite default token pattern '(?u)\\\\b\\\\w\\\\w+\\\\b'\n",
    "vectorizer = CountVectorizer(min_df=1, token_pattern='(?u)\\\\b\\\\w+\\\\b', binary=True)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bac0a15-0d69-4e8f-815d-e8b66f7e5851",
   "metadata": {},
   "source": [
    "Теперь мы видим, что размер наших векторов стал больше, и в словаре остались однобуквенные слова."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6c1b0-56ad-4e77-ad1b-4e996839b24c",
   "metadata": {},
   "source": [
    "## Векторы TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c657bd-3789-4433-87ac-85245880d5d9",
   "metadata": {},
   "source": [
    "Теперь мы можем воспользоваться другим из доступных в библиотеке _scikit-learn_ векторизаторов -- _TfidfVectorizer_, с помощью которого мы сможем представить нашу коллекцию текстов в виде векторов TF-IDF.\n",
    "\n",
    "_TfidfVectorizer_ очень похож на _CountVectorizer_, в т.ч. аналогичным образом позволяет кастомизировать предобработку текстов.\n",
    "\n",
    "Все детали можно найти в документации: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8509fa1-bffa-4007-bf21-15e5dc212232",
   "metadata": {},
   "source": [
    "Попробуем создать объект нашего векторизатора:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "942a4a47-3a85-4190-ad10-30d3b4c163f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=1, norm=None, smooth_idf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fdcf20e-17c7-452c-8ab5-e3e9c8ca91b8",
   "metadata": {},
   "source": [
    "Параметр norm=None говорит о том, что мы не хотим нормализовывать TF-IDF-векторы (по дефолту там используется L2-норма).\n",
    "\n",
    "Векторизуем нашу коллекцию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af524e0d-a85a-4df9-95a3-b97745d0fd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 17)\n",
      "['академия' 'государственная' 'государственный' 'им' 'институт'\n",
      " 'исследовательский' 'итмо' 'ломоносова' 'мгу' 'миэт' 'московская'\n",
      " 'московский' 'национальный' 'технический' 'университет' 'физико'\n",
      " 'хореографии']\n"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(texts)\n",
    "X = vectorizer.transform(texts)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c522364-489c-487d-a696-32acd831f0ec",
   "metadata": {},
   "source": [
    "Мы видим, что на выходе получилась матрица точно такого же размера, что и в прошлый раз.\n",
    "\n",
    "Однако ее элементы теперь выглядят по другому:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca180278-b8c1-428b-b3aa-555e68245ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.09861229 2.09861229 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         2.09861229 0.\n",
      "  0.         0.         0.         0.         2.09861229]\n",
      " [0.         0.         2.09861229 2.09861229 0.         0.\n",
      "  0.         2.09861229 2.09861229 0.         0.         1.69314718\n",
      "  0.         0.         2.36464311 0.         0.        ]\n",
      " [0.         0.         0.         0.         2.09861229 1.40546511\n",
      "  0.         0.         0.         0.         0.         1.69314718\n",
      "  1.40546511 2.09861229 1.18232156 2.09861229 0.        ]\n",
      " [0.         0.         0.         0.         0.         1.40546511\n",
      "  0.         0.         0.         2.09861229 0.         0.\n",
      "  1.40546511 0.         1.18232156 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         1.40546511\n",
      "  2.09861229 0.         0.         0.         0.         0.\n",
      "  1.40546511 0.         1.18232156 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865ee88d-f6bb-4338-a397-d138ede3b639",
   "metadata": {},
   "source": [
    "Теперь в каждой ячейке матрицы лежат не значения 0 (слова нет в тексте) или 1 (слово есть в тексте), а значения TF-IDF.\n",
    "\n",
    "А, с учетом того, что почти все TFы у нас равны 1, т.к. слова в текстах не повторяются (кроме слова УНИВЕРСИТЕТ во 2м документе), почти все TF-IDFы равны просто IDFам.\n",
    "\n",
    "Заметим, что с помощью _TfidfVectorizer_ мы получили те же самые значения IDFов, что и в предыдущем упражнении, когда считали их самостоятельно!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817b7b99-bbc9-485b-b5d8-d2b6c6837ae5",
   "metadata": {},
   "source": [
    "## Ранжирование с помощью TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0ed057-3167-4b04-a430-065c65a07495",
   "metadata": {},
   "source": [
    "Теперь перейдем к самому интересному: попробуем ранжировать наши документы, используя в качестве ранков косинусное расстояние между TF-IDF-векторами запросов и документов."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9f6447-819e-4b3f-aaf4-550d164c49d4",
   "metadata": {},
   "source": [
    "Допустим, у нас есть текстовый запрос query.\n",
    "\n",
    "Напишем функцию _search(query)_, которая:\n",
    "- векторизует наш запрос с помощью обученного ранее векторизатора\n",
    "- считаем попарную близость между вектором запроса и векторами документов\n",
    "- выводит на экран запрос и ранжированный список документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25474285-aa1f-4165-9fec-fda69f426d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "        # Vectorize query\n",
    "        X_query = vectorizer.transform([query])\n",
    "        \n",
    "        # Query-docs similarity\n",
    "        S = pairwise.cosine_similarity(X_query, X)\n",
    "        \n",
    "        # Rank docs\n",
    "        scores = S[0]\n",
    "        indexes = np.argsort(scores)[::-1]\n",
    "        ranked_docs = np.array(texts)[indexes]\n",
    "        ranked_doc_scores = scores[indexes]\n",
    "\n",
    "        # Output query and list of ranked docs\n",
    "        print(f\"query = '{query}'\")\n",
    "        for i, doc in enumerate(ranked_docs):\n",
    "            score = ranked_doc_scores[i]\n",
    "            print(f\"[{i}]: doc = '{doc}' score = {score:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4804e3-3717-497f-b156-fa77bbd64cdb",
   "metadata": {},
   "source": [
    "Применим нашу функцию к запросу \"университет\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c67b5fe8-5eb2-410b-8409-661f2d675721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query = 'университет'\n",
      "[0]: doc = 'Московский государственный университет им. М.В. Ломоносова (Университет МГУ)' score = 0.463\n",
      "[1]: doc = 'Национальный исследовательский университет ИТМО' score = 0.379\n",
      "[2]: doc = 'Национальный исследовательский университет «МИЭТ»' score = 0.379\n",
      "[3]: doc = 'Московский физико-технический институт (национальный исследовательский университет)' score = 0.255\n",
      "[4]: doc = 'Московская государственная академия хореографии' score = 0.000\n"
     ]
    }
   ],
   "source": [
    "search(\"университет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d44dc5f-a1d3-449f-935d-a3d074b5274a",
   "metadata": {},
   "source": [
    "Видим, что на 1м месте у нас МГУ, как и ожидалось.\n",
    "\n",
    "Попробуем другой запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a9bfe1-5817-4786-b227-0b714a2f8ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query = 'московский'\n",
      "[0]: doc = 'Московский физико-технический институт (национальный исследовательский университет)' score = 0.366\n",
      "[1]: doc = 'Московский государственный университет им. М.В. Ломоносова (Университет МГУ)' score = 0.332\n",
      "[2]: doc = 'Национальный исследовательский университет ИТМО' score = 0.000\n",
      "[3]: doc = 'Национальный исследовательский университет «МИЭТ»' score = 0.000\n",
      "[4]: doc = 'Московская государственная академия хореографии' score = 0.000\n"
     ]
    }
   ],
   "source": [
    "search(\"московский\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5ed20b-5ae6-4f73-af54-0f09aa2dab93",
   "metadata": {},
   "source": [
    "Обратим внимание, что на 1м месте у нас МФТИ -- это связано с тем, что полное название МФТИ короче, чем полное название МГУ, а в формуле косинусной близости у нас используются длины наших векторов.\n",
    "\n",
    "Таким образом, формула TF-IDF позволяет даже для однословных запросов отличать потенциально более релевантные документы от менее релевантных!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83a95e2-d7e7-4f5f-9183-99418bf8825c",
   "metadata": {},
   "source": [
    "Попробуем теперь многословный запрос:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa2671ff-1077-493c-b257-ce1b2e8ed0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query = 'московский университет'\n",
      "[0]: doc = 'Московский государственный университет им. М.В. Ломоносова (Университет МГУ)' score = 0.537\n",
      "[1]: doc = 'Московский физико-технический институт (национальный исследовательский университет)' score = 0.446\n",
      "[2]: doc = 'Национальный исследовательский университет ИТМО' score = 0.217\n",
      "[3]: doc = 'Национальный исследовательский университет «МИЭТ»' score = 0.217\n",
      "[4]: doc = 'Московская государственная академия хореографии' score = 0.000\n"
     ]
    }
   ],
   "source": [
    "search(\"московский университет\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db9dae8-8695-4e11-94b1-9e175a0bf5ee",
   "metadata": {},
   "source": [
    "Таким образом, мы научились ранжировать документы, используя модель векторного пространства и векторы TF-IDF!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
